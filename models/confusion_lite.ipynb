{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metadata and Text concatenated network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at digitalepidemiologylab/covid-twitter-bert-v2 were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at digitalepidemiologylab/covid-twitter-bert-v2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "import emoji\n",
    "import random\n",
    "import keras\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\") # make it possible to import functions from different files that are in folders a level up\n",
    "\n",
    "import os\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "from keras.models import Model\n",
    "from data.functions.string_tools import print_split_shapes\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from text.tools.bert_model import get_model, MAX_LEN\n",
    "\n",
    "# SEEDS\n",
    "random_state = 111\n",
    "\n",
    "os.environ['PYTHONHASHSEED'] = str(random_state)\n",
    "random.seed(random_state)\n",
    "np.random.seed(random_state)\n",
    "tf.random.set_seed(random_state)\n",
    "\n",
    "epochs = 8\n",
    "batch_size= 128\n",
    "txt_size= 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if a GPU is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU found\n"
     ]
    }
   ],
   "source": [
    "if tf.test.gpu_device_name():\n",
    "  print('GPU found')\n",
    "else:\n",
    "  print(\"No GPU found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>user_description</th>\n",
       "      <th>user_followers_count</th>\n",
       "      <th>user_friends_count</th>\n",
       "      <th>user_favourites_count</th>\n",
       "      <th>user_statuses_count</th>\n",
       "      <th>user_media_count</th>\n",
       "      <th>hashtags_count</th>\n",
       "      <th>username</th>\n",
       "      <th>...</th>\n",
       "      <th>part_of_thread</th>\n",
       "      <th>tweet_sentiment</th>\n",
       "      <th>user_creation_tweet_diff</th>\n",
       "      <th>tweeted_in_daypart_day</th>\n",
       "      <th>tweeted_in_daypart_evening</th>\n",
       "      <th>tweeted_in_daypart_morning</th>\n",
       "      <th>tweeted_in_daypart_night</th>\n",
       "      <th>user_created_in_daypart_day</th>\n",
       "      <th>user_created_in_daypart_evening</th>\n",
       "      <th>real_fake_grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our daily update is published. States reported...</td>\n",
       "      <td>171</td>\n",
       "      <td>We try to provide the most comprehensive state...</td>\n",
       "      <td>468030</td>\n",
       "      <td>13</td>\n",
       "      <td>85</td>\n",
       "      <td>2594</td>\n",
       "      <td>1364</td>\n",
       "      <td>0</td>\n",
       "      <td>The COVID Tracking Project</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16384932</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>President Trump Asked What He Would Do If He W...</td>\n",
       "      <td>0</td>\n",
       "      <td>Spoof news, political satire, parody and more!...</td>\n",
       "      <td>803</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>57502</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>The Spoof</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>293776787</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>States reported 630 deaths. We are still seein...</td>\n",
       "      <td>71</td>\n",
       "      <td>We try to provide the most comprehensive state...</td>\n",
       "      <td>468030</td>\n",
       "      <td>13</td>\n",
       "      <td>85</td>\n",
       "      <td>2594</td>\n",
       "      <td>1364</td>\n",
       "      <td>0</td>\n",
       "      <td>The COVID Tracking Project</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9039963</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Low #vitaminD was an independent predictor of ...</td>\n",
       "      <td>40</td>\n",
       "      <td>Medscape provides breaking medical news and ex...</td>\n",
       "      <td>215969</td>\n",
       "      <td>39457</td>\n",
       "      <td>2206</td>\n",
       "      <td>49892</td>\n",
       "      <td>16563</td>\n",
       "      <td>1</td>\n",
       "      <td>Medscape</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>375950159</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A common question: why are the cumulative outc...</td>\n",
       "      <td>0</td>\n",
       "      <td>We try to provide the most comprehensive state...</td>\n",
       "      <td>468030</td>\n",
       "      <td>13</td>\n",
       "      <td>85</td>\n",
       "      <td>2594</td>\n",
       "      <td>1364</td>\n",
       "      <td>1</td>\n",
       "      <td>The COVID Tracking Project</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2470004</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           full_text  retweet_count  \\\n",
       "0  Our daily update is published. States reported...            171   \n",
       "1  President Trump Asked What He Would Do If He W...              0   \n",
       "2  States reported 630 deaths. We are still seein...             71   \n",
       "3  Low #vitaminD was an independent predictor of ...             40   \n",
       "4  A common question: why are the cumulative outc...              0   \n",
       "\n",
       "                                    user_description  user_followers_count  \\\n",
       "0  We try to provide the most comprehensive state...                468030   \n",
       "1  Spoof news, political satire, parody and more!...                   803   \n",
       "2  We try to provide the most comprehensive state...                468030   \n",
       "3  Medscape provides breaking medical news and ex...                215969   \n",
       "4  We try to provide the most comprehensive state...                468030   \n",
       "\n",
       "   user_friends_count  user_favourites_count  user_statuses_count  \\\n",
       "0                  13                     85                 2594   \n",
       "1                  97                      1                57502   \n",
       "2                  13                     85                 2594   \n",
       "3               39457                   2206                49892   \n",
       "4                  13                     85                 2594   \n",
       "\n",
       "   user_media_count  hashtags_count                    username  ...  \\\n",
       "0              1364               0  The COVID Tracking Project  ...   \n",
       "1                 3               2                   The Spoof  ...   \n",
       "2              1364               0  The COVID Tracking Project  ...   \n",
       "3             16563               1                    Medscape  ...   \n",
       "4              1364               1  The COVID Tracking Project  ...   \n",
       "\n",
       "   part_of_thread  tweet_sentiment  user_creation_tweet_diff  \\\n",
       "0               0                0                  16384932   \n",
       "1               0                0                 293776787   \n",
       "2               1                0                   9039963   \n",
       "3               0                1                 375950159   \n",
       "4               1                2                   2470004   \n",
       "\n",
       "   tweeted_in_daypart_day  tweeted_in_daypart_evening  \\\n",
       "0                       0                           1   \n",
       "1                       1                           0   \n",
       "2                       0                           1   \n",
       "3                       0                           0   \n",
       "4                       0                           1   \n",
       "\n",
       "   tweeted_in_daypart_morning  tweeted_in_daypart_night  \\\n",
       "0                           0                         0   \n",
       "1                           0                         0   \n",
       "2                           0                         0   \n",
       "3                           0                         1   \n",
       "4                           0                         0   \n",
       "\n",
       "   user_created_in_daypart_day  user_created_in_daypart_evening  \\\n",
       "0                            0                                0   \n",
       "1                            0                                0   \n",
       "2                            0                                0   \n",
       "3                            0                                1   \n",
       "4                            0                                0   \n",
       "\n",
       "   real_fake_grade  \n",
       "0              1.0  \n",
       "1             -1.0  \n",
       "2              1.0  \n",
       "3              1.0  \n",
       "4              1.0  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_path = '../data/selected_data/all_data_selected.csv'\n",
    "\n",
    "df = pd.read_csv(folder_path)\n",
    "\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop duplicated and not set fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7905, 44)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7816, 44)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['user_description'] = df['user_description'].apply(lambda x: x if pd.notna(x) else '')\n",
    "print(df.shape)\n",
    "df = df.dropna(subset=['full_text']).drop_duplicates(subset=['full_text'])\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine text fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_text</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>user_followers_count</th>\n",
       "      <th>user_friends_count</th>\n",
       "      <th>user_favourites_count</th>\n",
       "      <th>user_statuses_count</th>\n",
       "      <th>user_media_count</th>\n",
       "      <th>hashtags_count</th>\n",
       "      <th>has_user_url</th>\n",
       "      <th>text_length</th>\n",
       "      <th>...</th>\n",
       "      <th>user_creation_tweet_diff</th>\n",
       "      <th>tweeted_in_daypart_day</th>\n",
       "      <th>tweeted_in_daypart_evening</th>\n",
       "      <th>tweeted_in_daypart_morning</th>\n",
       "      <th>tweeted_in_daypart_night</th>\n",
       "      <th>user_created_in_daypart_day</th>\n",
       "      <th>user_created_in_daypart_evening</th>\n",
       "      <th>real_fake_grade</th>\n",
       "      <th>text</th>\n",
       "      <th>user_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our daily update is published. States reported...</td>\n",
       "      <td>171</td>\n",
       "      <td>468030</td>\n",
       "      <td>13</td>\n",
       "      <td>85</td>\n",
       "      <td>2594</td>\n",
       "      <td>1364</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>...</td>\n",
       "      <td>16384932</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Our daily update is published. States reported...</td>\n",
       "      <td>The COVID Tracking Project We try to provide t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>President Trump Asked What He Would Do If He W...</td>\n",
       "      <td>0</td>\n",
       "      <td>803</td>\n",
       "      <td>97</td>\n",
       "      <td>1</td>\n",
       "      <td>57502</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>125</td>\n",
       "      <td>...</td>\n",
       "      <td>293776787</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>President Trump Asked What He Would Do If He W...</td>\n",
       "      <td>The Spoof Spoof news, political satire, parody...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>States reported 630 deaths. We are still seein...</td>\n",
       "      <td>71</td>\n",
       "      <td>468030</td>\n",
       "      <td>13</td>\n",
       "      <td>85</td>\n",
       "      <td>2594</td>\n",
       "      <td>1364</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>245</td>\n",
       "      <td>...</td>\n",
       "      <td>9039963</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>States reported 630 deaths. We are still seein...</td>\n",
       "      <td>The COVID Tracking Project We try to provide t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Low #vitaminD was an independent predictor of ...</td>\n",
       "      <td>40</td>\n",
       "      <td>215969</td>\n",
       "      <td>39457</td>\n",
       "      <td>2206</td>\n",
       "      <td>49892</td>\n",
       "      <td>16563</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>112</td>\n",
       "      <td>...</td>\n",
       "      <td>375950159</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Low #vitaminD was an independent predictor of ...</td>\n",
       "      <td>Medscape Medscape provides breaking medical ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A common question: why are the cumulative outc...</td>\n",
       "      <td>0</td>\n",
       "      <td>468030</td>\n",
       "      <td>13</td>\n",
       "      <td>85</td>\n",
       "      <td>2594</td>\n",
       "      <td>1364</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>277</td>\n",
       "      <td>...</td>\n",
       "      <td>2470004</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A common question: why are the cumulative outc...</td>\n",
       "      <td>The COVID Tracking Project We try to provide t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           full_text  retweet_count  \\\n",
       "0  Our daily update is published. States reported...            171   \n",
       "1  President Trump Asked What He Would Do If He W...              0   \n",
       "2  States reported 630 deaths. We are still seein...             71   \n",
       "3  Low #vitaminD was an independent predictor of ...             40   \n",
       "4  A common question: why are the cumulative outc...              0   \n",
       "\n",
       "   user_followers_count  user_friends_count  user_favourites_count  \\\n",
       "0                468030                  13                     85   \n",
       "1                   803                  97                      1   \n",
       "2                468030                  13                     85   \n",
       "3                215969               39457                   2206   \n",
       "4                468030                  13                     85   \n",
       "\n",
       "   user_statuses_count  user_media_count  hashtags_count  has_user_url  \\\n",
       "0                 2594              1364               0             1   \n",
       "1                57502                 3               2             1   \n",
       "2                 2594              1364               0             1   \n",
       "3                49892             16563               1             1   \n",
       "4                 2594              1364               1             1   \n",
       "\n",
       "   text_length  ...  user_creation_tweet_diff  tweeted_in_daypart_day  \\\n",
       "0          163  ...                  16384932                       0   \n",
       "1          125  ...                 293776787                       1   \n",
       "2          245  ...                   9039963                       0   \n",
       "3          112  ...                 375950159                       0   \n",
       "4          277  ...                   2470004                       0   \n",
       "\n",
       "   tweeted_in_daypart_evening  tweeted_in_daypart_morning  \\\n",
       "0                           1                           0   \n",
       "1                           0                           0   \n",
       "2                           1                           0   \n",
       "3                           0                           0   \n",
       "4                           1                           0   \n",
       "\n",
       "   tweeted_in_daypart_night  user_created_in_daypart_day  \\\n",
       "0                         0                            0   \n",
       "1                         0                            0   \n",
       "2                         0                            0   \n",
       "3                         1                            0   \n",
       "4                         0                            0   \n",
       "\n",
       "   user_created_in_daypart_evening  real_fake_grade  \\\n",
       "0                                0              1.0   \n",
       "1                                0             -1.0   \n",
       "2                                0              1.0   \n",
       "3                                1              1.0   \n",
       "4                                0              1.0   \n",
       "\n",
       "                                                text  \\\n",
       "0  Our daily update is published. States reported...   \n",
       "1  President Trump Asked What He Would Do If He W...   \n",
       "2  States reported 630 deaths. We are still seein...   \n",
       "3  Low #vitaminD was an independent predictor of ...   \n",
       "4  A common question: why are the cumulative outc...   \n",
       "\n",
       "                                           user_info  \n",
       "0  The COVID Tracking Project We try to provide t...  \n",
       "1  The Spoof Spoof news, political satire, parody...  \n",
       "2  The COVID Tracking Project We try to provide t...  \n",
       "3  Medscape Medscape provides breaking medical ne...  \n",
       "4  The COVID Tracking Project We try to provide t...  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'] = df['full_text']\n",
    "df['user_info'] = df['username'] + ' ' + df['user_description']\n",
    "\n",
    "df.drop(['username', 'user_description'], axis=1, inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "\n",
    "    # vervang alle urls\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', 'HTTPADDR', text)\n",
    "    \n",
    "    # verwijder punctuation\n",
    "    text = text.translate(str.maketrans('','', string.punctuation))\n",
    "    # vervang emojis door  'EMOJI'\n",
    "    text = emoji.demojize(text)\n",
    "    text = re.sub(r\"\\:(.*?)\\:\", ' EMOJI ',text)\n",
    "    # vervang getallen door 'NUMMER'\n",
    "    text = re.sub(r\"\\b[\\d.]+\\b\", \" NUMMER \", text)\n",
    "    # vervang opeenvolgende spaties en tabs door een enkele spatie\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "\n",
    "    # Removing the stopwords from text\n",
    "    new_text = []\n",
    "\n",
    "    tokenized = word_tokenize(text)\n",
    "\n",
    "    for word in tokenized:\n",
    "        if word not in stop_words:\n",
    "            word = word.strip() # haal spaties aan uiteinde weg\n",
    "            word = lemmatizer.lemmatize(word) # rocks -> rock, better -> good, running -> run\n",
    "            new_text.append(word)\n",
    "\n",
    "    \n",
    "    \n",
    "    text = ' '.join(lemmatizer.lemmatize(word) for word in tokenized if word not in stop_words)\n",
    "    \n",
    "\n",
    "    # verwijder onnodige spaties aan begin en eind\n",
    "    text = text.strip()\n",
    "\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before:\n",
      "@globaltimesnews It doesn’t effect randians coz they have CowUrine for cure🐄💦💁🏿‍♂️ after all they have bad smell to tackle COVID-19 with Cow-dung\n",
      "\n",
      "after:\n",
      "globaltimesnews ’ effect randians coz cowurine cure EMOJI EMOJI EMOJI bad smell tackle covid19 cowdung\n"
     ]
    }
   ],
   "source": [
    "print('before:')\n",
    "print(df['text'][74])\n",
    "\n",
    "print('\\nafter:')\n",
    "print(clean_text(df['text'][74]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(clean_text)\n",
    "df['full_text'] = df['full_text'].apply(clean_text)\n",
    "df['user_info'] = df['user_info'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_text:  (7816, 2) \n",
      "x_meta_data (7816, 44) \n",
      "y (7816,)\n"
     ]
    }
   ],
   "source": [
    "x_text = df[['text', 'user_info']]\n",
    "\n",
    "x_meta_data = df\n",
    "# x_meta_data= df.drop(axis=1, columns=['real_fake_grade', 'text', 'user_info', 'full_text'])\n",
    "\n",
    "y = df['real_fake_grade']\n",
    "\n",
    "print('x_text: ', x_text.shape, '\\nx_meta_data', x_meta_data.shape, '\\ny', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into metadata and text sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_meta_data, x_test_meta_data, x_train_text, x_test_text = train_test_split(x_meta_data, x_text, test_size=.2, random_state=random_state)\n",
    "\n",
    "x_train_user_info = x_train_text['user_info']\n",
    "x_test_user_info = x_test_text['user_info']\n",
    "\n",
    "x_train_tweet = x_train_text['text']\n",
    "x_test_tweet = x_test_text['text']\n",
    "\n",
    "y_train = x_train_meta_data['real_fake_grade'].values\n",
    "y_test = x_test_meta_data['real_fake_grade'].values\n",
    "\n",
    "x_train_meta_data = x_train_meta_data.drop(axis=1, columns=['real_fake_grade', 'text', 'user_info', 'full_text'])\n",
    "x_test_meta_data = x_test_meta_data.drop(axis=1, columns=['real_fake_grade', 'text', 'user_info', 'full_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta data shapes:\n",
      "Train shapes\n",
      "\tX:(6252, 40)\n",
      "\ty:(6252,)\n",
      "Test shapes\n",
      "\tX:(1564, 40)\n",
      "\ty:(1564,)\n",
      "Tweet data shapes:\n",
      "Train shapes\n",
      "\tX:(6252, 2)\n",
      "\ty:(6252,)\n",
      "Test shapes\n",
      "\tX:(1564, 2)\n",
      "\ty:(1564,)\n",
      "User info data shapes:\n",
      "Train shapes\n",
      "\tX:(6252,)\n",
      "\ty:(6252,)\n",
      "Test shapes\n",
      "\tX:(1564,)\n",
      "\ty:(1564,)\n"
     ]
    }
   ],
   "source": [
    "def print_shapes():\n",
    "  print('Meta data shapes:')\n",
    "  print_split_shapes(x_train_meta_data, y_train, x_test_meta_data, y_test)\n",
    "\n",
    "  print('Tweet data shapes:')\n",
    "  print_split_shapes(x_train_text, y_train, x_test_text, y_test)\n",
    "\n",
    "  print('User info data shapes:')\n",
    "  print_split_shapes(x_train_user_info, y_train, x_test_user_info, y_test)\n",
    "\n",
    "print_shapes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform the data into better (machine) readable sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta data shapes:\n",
      "Train shapes\n",
      "\tX:(6252, 40)\n",
      "\ty:(6252,)\n",
      "Test shapes\n",
      "\tX:(1564, 40)\n",
      "\ty:(1564,)\n",
      "Tweet data shapes:\n",
      "Train shapes\n",
      "\tX:(6252, 2)\n",
      "\ty:(6252,)\n",
      "Test shapes\n",
      "\tX:(1564, 2)\n",
      "\ty:(1564,)\n",
      "User info data shapes:\n",
      "Train shapes\n",
      "\tX:(6252,)\n",
      "\ty:(6252,)\n",
      "Test shapes\n",
      "\tX:(1564,)\n",
      "\ty:(1564,)\n"
     ]
    }
   ],
   "source": [
    "# scale the metadata\n",
    "scaler = StandardScaler()\n",
    "\n",
    "x_train_meta_data = scaler.fit_transform(x_train_meta_data)\n",
    "x_test_meta_data = scaler.transform(x_test_meta_data)\n",
    "\n",
    "# the y labels contains 3 possible values, -1, 0 and 1. Negative labels are not accepted by a neural net so these must be transformed\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.transform(y_test)\n",
    "\n",
    "print_shapes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('digitalepidemiologylab/covid-twitter-bert-v2')\n",
    "\n",
    "def tokenize(X):\n",
    "  return tokenizer(\n",
    "    text=X.tolist(),\n",
    "    add_special_tokens=True,\n",
    "    max_length=MAX_LEN,\n",
    "    truncation=True,\n",
    "    padding=True, \n",
    "    return_tensors='tf',\n",
    "    return_token_type_ids = False,\n",
    "    return_attention_mask = True,\n",
    "    verbose = True\n",
    "  )\n",
    "\n",
    "# Tokenize the input (takes some time)\n",
    "x_train_tweet_tokenized = tokenize(x_train_tweet)\n",
    "x_test_tweet_tokenized = tokenize(x_test_tweet)\n",
    "\n",
    "x_train_user_text_tokenized = tokenize(x_train_user_info)\n",
    "x_test_user_text_tokenized = tokenize(x_test_user_info)\n",
    "\n",
    "bert_train_tweet_input = { 'input_ids': x_train_tweet_tokenized['input_ids'], 'attention_mask': x_train_tweet_tokenized['attention_mask'] }\n",
    "bert_test_tweet_input = { 'input_ids': x_test_tweet_tokenized['input_ids'], 'attention_mask': x_test_tweet_tokenized['attention_mask'] }\n",
    "\n",
    "bert_train_user_text_input = { 'input_ids': x_train_user_text_tokenized['input_ids'], 'attention_mask': x_train_user_text_tokenized['attention_mask'] }\n",
    "bert_test_user_text_input = { 'input_ids': x_test_user_text_tokenized['input_ids'], 'attention_mask': x_test_user_text_tokenized['attention_mask'] }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building\n",
    "For the model building we are going to use three different combinations for concatenation\n",
    "\n",
    "- metadata (nn) + user_info bert\n",
    "- metadata (nn) + tweet bert\n",
    "- metadata (nn) + user_info bert + tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate the two networks into one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare the models for concatenation\n",
    "\n",
    "The two pre-trained models (nn and bert) are functional models, meaning that they have an output layer ready for classification and all the parameters have been trained.<br>\n",
    "For the concatenation process we do not require an output layer for each network, so we pop it off. And we also set all the parameters to not trainable since they have already been trained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Used functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(network: Model, x_test: list, name: str) -> pd.DataFrame:\n",
    "  predictions = network.predict(x_test)\n",
    "\n",
    "  return pd.DataFrame({\n",
    "    'Name': [name],\n",
    "    'Predictions': [predictions]\n",
    "  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)         [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " attention_mask (InputLayer)    [(None, 128)]        0           []                               \n",
      "                                                                                                  \n",
      " tf_bert_model (TFBertModel)    TFBaseModelOutputWi  335141888   ['input_ids[0][0]',              \n",
      "                                thPoolingAndCrossAt               'attention_mask[0][0]']         \n",
      "                                tentions(last_hidde                                               \n",
      "                                n_state=(None, 128,                                               \n",
      "                                 1024),                                                           \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 1024),                                                         \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 128)          131200      ['tf_bert_model[0][1]']          \n",
      "                                                                                                  \n",
      " dropout_74 (Dropout)           (None, 128)          0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 32)           4128        ['dropout_74[0][0]']             \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 3)            99          ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 335,277,315\n",
      "Trainable params: 335,277,315\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bert_user_info = get_model()\n",
    "\n",
    "bert_user_info.load_weights('./text/bert-text-metadata-weights.h5')\n",
    "\n",
    "bert_user_info.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BERT</td>\n",
       "      <td>[[0.006881526, 0.0077838516, 0.98533463], [0.2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Name                                        Predictions\n",
       "0  BERT  [[0.006881526, 0.0077838516, 0.98533463], [0.2..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_pred = predict(bert_user_info, bert_test_user_text_input, 'BERT')\n",
    "\n",
    "bert_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_72 (Dense)            (None, 512)               20992     \n",
      "                                                                 \n",
      " dropout_60 (Dropout)        (None, 512)               0         \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_61 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_74 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_62 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_75 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_63 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_76 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_64 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_77 (Dense)            (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 195,651\n",
      "Trainable params: 195,651\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nn_model = keras.models.load_model('./metadata/nn_model.h5')\n",
    "\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Metadata</td>\n",
       "      <td>[[0.99999976, 9.321629e-08, 1.17567716e-07], [...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Name                                        Predictions\n",
       "0  Metadata  [[0.99999976, 9.321629e-08, 1.17567716e-07], [..."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_pred = predict(nn_model, x_test_meta_data, 'Metadata')\n",
    "\n",
    "nn_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_pred(entry):\n",
    "    \"\"\"returns the softmax index of the entry for accuracy score\"\"\"\n",
    "    softmax = max(entry)\n",
    "    list = entry.tolist()\n",
    "    index = list.index(softmax)\n",
    "    return index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 2, 2, 0]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert(values):\n",
    "  converted = []\n",
    "  for pred in values:\n",
    "    converted.append(np.argmax(pred))\n",
    "\n",
    "  return converted\n",
    "\n",
    "nn_converted = convert(nn_pred['Predictions'].values[0])\n",
    "\n",
    "nn_converted[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 1, 1, 1, 2]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_converted = convert(bert_pred['Predictions'].values[0])\n",
    "\n",
    "bert_converted[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1, -1, 1, 1, -1]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_converted = [pred - 1 for pred in nn_converted]\n",
    "\n",
    "nn_converted[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1, 1, 1, 1, -1]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_converted = [-1 if pred == 2 else pred for pred in bert_converted]\n",
    "\n",
    "bert_converted[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1, -1, 1, 1, -1]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_values = y_test\n",
    "\n",
    "test_values = test_values - 1\n",
    "\n",
    "test_values = list(test_values)\n",
    "\n",
    "test_values[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1564"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nn_converted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1564"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bert_converted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_indexes = []\n",
    "fake_indexes = []\n",
    "neutral_indexes = []\n",
    "\n",
    "for index in range(len(test_values)):\n",
    "  val = test_values[index]\n",
    "\n",
    "  if val == 1:\n",
    "    real_indexes.append(index)\n",
    "  elif val == 0:\n",
    "    neutral_indexes.append(index)\n",
    "  else:\n",
    "    fake_indexes.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 6, 7, 10]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_indexes[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 4, 5, 11]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_indexes[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 9, 12, 14, 17]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neutral_indexes[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "both incc: 25\n",
      "both corr: 296\n"
     ]
    }
   ],
   "source": [
    "fake_both_correct = 0\n",
    "fake_metadata_correct_data_incorrect = 0\n",
    "fake_metadata_incorrect_correct_data_correct = 0\n",
    "fake_both_incorrect = 0\n",
    "\n",
    "neutral_both_correct = 0\n",
    "neutral_metadata_correct_data_incorrect = 0\n",
    "neutral_metadata_incorrect_correct_data_correct = 0\n",
    "neutral_both_incorrect = 0\n",
    "\n",
    "true_both_correct = 0\n",
    "true_metadata_correct_data_incorrect = 0\n",
    "true_metadata_incorrect_correct_data_correct = 0\n",
    "true_both_incorrect = 0\n",
    "\n",
    "# index:\n",
    "# 0 == both true\n",
    "# 1 == bert true, nn false\n",
    "# 2 == nn true, bert false\n",
    "# 3 == both false\n",
    "\n",
    "for true_value, nn, bert in zip(test_values, nn_converted, bert_converted):\n",
    "  if true_value == -1:\n",
    "    if nn == true_value and bert == true_value:\n",
    "      fake_both_correct += 1\n",
    "    elif bert == true_value and not nn == true_value:\n",
    "      fake_metadata_incorrect_correct_data_correct += 1 \n",
    "    elif nn == true_value and not bert == true_value:\n",
    "      fake_metadata_correct_data_incorrect += 1\n",
    "    else:\n",
    "      fake_both_incorrect += 1\n",
    "  if true_value == 0:\n",
    "    if nn == true_value and bert == true_value:\n",
    "      neutral_both_correct += 1\n",
    "    elif bert == true_value and not nn == true_value:\n",
    "      neutral_metadata_incorrect_correct_data_correct += 1 \n",
    "    elif nn == true_value and not bert == true_value:\n",
    "      neutral_metadata_correct_data_incorrect += 1\n",
    "    else:\n",
    "      neutral_both_incorrect += 1\n",
    "  if true_value == 1:\n",
    "    if nn == true_value and bert == true_value:\n",
    "      true_both_correct += 1\n",
    "    elif bert == true_value and not nn == true_value:\n",
    "      true_metadata_incorrect_correct_data_correct += 1 \n",
    "    elif nn == true_value and not bert == true_value:\n",
    "      true_metadata_correct_data_incorrect += 1\n",
    "    else:\n",
    "      true_both_incorrect += 1\n",
    "\n",
    "print(f'both incc: {fake_both_incorrect}\\nboth corr: {fake_both_correct}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([  2,   1,  46, 143]),\n",
       " array([757,  98,  59,  24]),\n",
       " array([296,  26,  87,  25])]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = [None, None, None]\n",
    "test = [-1,0,1]\n",
    "\n",
    "for i in test:\n",
    "  arr = [0,0,0,0]\n",
    "  values[i] = []\n",
    "\n",
    "  for true_value, nn, bert in zip(test_values, nn_converted, bert_converted):\n",
    "    if true_value == i:\n",
    "      if nn == true_value and bert == true_value:\n",
    "        arr[0] += 1\n",
    "      elif bert == true_value and not nn == true_value:\n",
    "        arr[1] += 1\n",
    "      elif nn == true_value and not bert == true_value:\n",
    "        arr[2] += 1\n",
    "      else:\n",
    "        arr[3] += 1\n",
    "\n",
    "  values[i] = np.array(arr)\n",
    "\n",
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "938"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_count = len(real_indexes)\n",
    "\n",
    "real_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "434"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_count = len(fake_indexes)\n",
    "fake_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neutral_count = len(neutral_indexes)\n",
    "neutral_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = [\n",
    "  np.array([\n",
    "    fake_both_correct,\n",
    "    fake_metadata_correct_data_incorrect,\n",
    "    fake_metadata_incorrect_correct_data_correct,\n",
    "    fake_both_incorrect]\n",
    "  ),\n",
    "  np.array([\n",
    "    neutral_both_correct,\n",
    "    neutral_metadata_correct_data_incorrect,\n",
    "    neutral_metadata_incorrect_correct_data_correct,\n",
    "    neutral_both_incorrect]\n",
    "  ),\n",
    "  np.array([\n",
    "    true_both_correct,\n",
    "    true_metadata_correct_data_incorrect,\n",
    "    true_metadata_incorrect_correct_data_correct,\n",
    "    true_both_incorrect]\n",
    "  )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = []\n",
    "n = []\n",
    "r = []\n",
    "for index, t in enumerate(counts):\n",
    "  if index == 0:\n",
    "    # fake\n",
    "    f = np.round(t / fake_count * 100)\n",
    "  elif index == 1:\n",
    "    # neutral\n",
    "    n = np.round(t / neutral_count * 100)\n",
    "  else:\n",
    "    # true\n",
    "    r = np.round(t / real_count * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oplaan in onderzoeksrapport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([68., 20.,  6.,  6.])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1., 24.,  1., 74.])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([81.,  6., 10.,  3.])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4047f7eda800f5efa8437172d07800da7973adca17d077c4d1b0c239621dfa84"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
